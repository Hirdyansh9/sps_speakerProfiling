{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747127992666,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "aA57GbujC8sh"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747127992668,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "fZXfE8llC8pq"
   },
   "outputs": [],
   "source": [
    "# !mkdir 'timit_dataset'\n",
    "# !unzip '/content/drive/MyDrive/sps/preprocessed_timit_dataset.zip' -d timit_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8276,
     "status": "ok",
     "timestamp": 1747128000946,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "ZZz1Hh0rC8my"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor, logging as hf_logging\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747128000951,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "XE68ZQ8AYb9x"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747128000954,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "HvIMzMd5DPhN"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "hf_logging.set_verbosity_error()\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yURAM6Tm35Pb"
   },
   "source": [
    "For this config, L4 GPU is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747128000957,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "PNntAev9wsnc"
   },
   "outputs": [],
   "source": [
    "AUDIO_ROOT_DIR = '/content/timit_dataset'\n",
    "DRIVE_PATH = '/content/drive/MyDrive/sps/'\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(DRIVE_PATH, 'final_train_data_merged.csv')\n",
    "TEST_CSV_PATH = os.path.join(DRIVE_PATH, 'final_test_data_merged.csv')\n",
    "CKPT_PATH = os.path.join(DRIVE_PATH, 'sps_bilstm_best_model.pth')\n",
    "\n",
    "# Audio Processing\n",
    "SAMPLE_RATE = 16000\n",
    "CLIP_SECONDS = 4.0\n",
    "WAV_LEN = int(SAMPLE_RATE * CLIP_SECONDS)\n",
    "\n",
    "# Audio Augmentations\n",
    "APPLY_AUGMENTATIONS = True\n",
    "AUGMENTATION_PROBABILITY = 0.20\n",
    "ADD_NOISE_PROBABILITY = 0.20\n",
    "NOISE_SNR_MIN = 5.0\n",
    "NOISE_SNR_MAX = 20.0\n",
    "\n",
    "# Wav2Vec2.0 Base Model\n",
    "PRETRAINED_W2V2 = 'facebook/wav2vec2-base-960h'\n",
    "W2V2_OUTPUT_DIM = 768\n",
    "FREEZE_ENCODER = True\n",
    "\n",
    "# BiLSTM Specific Parameters\n",
    "LSTM_HIDDEN_SIZE = 256\n",
    "LSTM_NUM_LAYERS = 4\n",
    "\n",
    "# Dropout\n",
    "MODEL_DROPOUT_RATE = 0.3\n",
    "\n",
    "# Training Hyperparameters\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 3e-4\n",
    "OPTIMIZER_WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Validation\n",
    "VAL_SPLIT_RATIO = 0.3\n",
    "VAL_SPLIT_SEED = 42\n",
    "\n",
    "# Task Configuration\n",
    "TASKS = {\n",
    "    'age': {'type': 'regression', 'loss_weight': 0.4},\n",
    "    'Gender': {'type': 'classification', 'loss_weight': 0.4},\n",
    "    'height': {'type': 'regression', 'loss_weight': 0.2}\n",
    "}\n",
    "\n",
    "# Head-Specific Hyperparameters\n",
    "HEAD_CONFIGS = {\n",
    "    'age': {'head_hidden_dim': 128, 'head_dropout_rate': 0.3},\n",
    "    'Gender': {'head_hidden_dim': 128, 'head_dropout_rate': 0.3},\n",
    "    'height': {'head_hidden_dim': 64, 'head_dropout_rate': 0.2}\n",
    "}\n",
    "\n",
    "# Mappings and Normalization Stats\n",
    "GENDER_MAP = {}\n",
    "NORM_STATS = {\n",
    "    'age': {'mean': 0.0, 'std': 1.0},\n",
    "    'height': {'mean': 0.0, 'std': 1.0}\n",
    "}\n",
    "\n",
    "# DataLoader\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True if DEVICE == 'cuda' else False\n",
    "\n",
    "# --- Model Saving, Early Stopping, LR Scheduling ---\n",
    "MONITOR_METRIC_MODE = 'min'\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "LR_SCHEDULER_PATIENCE = 5\n",
    "LR_SCHEDULER_FACTOR = 0.1\n",
    "MIN_LR = 3e-5\n",
    "\n",
    "\n",
    "EVAL_LOSS_WEIGHTS = {\n",
    "    'age': 0.45,\n",
    "    'Gender': 0.45,\n",
    "    'height': 0.10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747128000959,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "bstWZGsZww1C"
   },
   "outputs": [],
   "source": [
    "class PadCrop:\n",
    "    def __init__(self, length, mode = 'train'):\n",
    "        self.length = length\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        current_len = wav.shape[-1]\n",
    "        if current_len == self.length:\n",
    "            return wav\n",
    "        elif current_len > self.length:\n",
    "            if self.mode == 'train':\n",
    "                start = random.randint(0, current_len - self.length)\n",
    "            else:\n",
    "                start = (current_len - self.length) // 2\n",
    "            wav = wav[..., start : start + self.length]\n",
    "        else:\n",
    "            pad_width = self.length - current_len\n",
    "            pad_left = pad_width // 2\n",
    "            pad_right = pad_width - pad_left\n",
    "            wav = F.pad(wav, (pad_left, pad_right), mode='constant', value=0.0)\n",
    "        return wav\n",
    "\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, min_snr_db = 5.0, max_snr_db = 20.0, p = 0.5):\n",
    "        self.min_snr_db = min_snr_db\n",
    "        self.max_snr_db = max_snr_db\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, waveform):\n",
    "        if random.random() < self.p:\n",
    "            if waveform.ndim > 1 and waveform.shape[0] > 1:\n",
    "                wav_data_for_power_calc = waveform[0,:]\n",
    "            elif waveform.ndim > 1 and waveform.shape[0] == 1:\n",
    "                wav_data_for_power_calc = waveform.squeeze(0)\n",
    "            elif waveform.ndim == 1:\n",
    "                wav_data_for_power_calc = waveform\n",
    "            else:\n",
    "                return waveform\n",
    "\n",
    "            signal_power = torch.mean(wav_data_for_power_calc**2)\n",
    "            if signal_power.item() < 1e-9:\n",
    "                return waveform\n",
    "\n",
    "            snr_db = random.uniform(self.min_snr_db, self.max_snr_db)\n",
    "            snr_linear = 10**(snr_db / 10.0)\n",
    "            noise_power = signal_power / snr_linear\n",
    "            noise = torch.randn_like(waveform) * torch.sqrt(noise_power)\n",
    "            return waveform + noise\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747128000961,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "2vxC_q2RxAxC"
   },
   "outputs": [],
   "source": [
    "class TimitDataset(Dataset):\n",
    "    def __init__(self, data_df, mode= 'train'):\n",
    "        self.data_df = data_df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.pad_crop = PadCrop(WAV_LEN, mode)\n",
    "        self.target_cols = list(TASKS.keys())\n",
    "\n",
    "        self.add_noise_transform = None\n",
    "        if self.mode == 'train' and APPLY_AUGMENTATIONS:\n",
    "            self.add_noise_transform = AddGaussianNoise(\n",
    "                min_snr_db=NOISE_SNR_MIN,\n",
    "                max_snr_db=NOISE_SNR_MAX,\n",
    "                p=ADD_NOISE_PROBABILITY\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.data_df):\n",
    "            print(f\"Index {idx} out of bounds for dataset size {len(self.data_df)}\")\n",
    "            return None\n",
    "\n",
    "        row = self.data_df.iloc[idx]\n",
    "        wav_relative_path = row['FilePath']\n",
    "        full_wav_path = os.path.normpath(os.path.join(AUDIO_ROOT_DIR, wav_relative_path))\n",
    "\n",
    "        wav, sr = torchaudio.load(full_wav_path)\n",
    "\n",
    "        if sr != SAMPLE_RATE:\n",
    "            resampler = torchaudio.transforms.Resample(sr, SAMPLE_RATE)\n",
    "            wav = resampler(wav)\n",
    "\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "\n",
    "        if self.mode == 'train' and APPLY_AUGMENTATIONS:\n",
    "            if random.random() < AUGMENTATION_PROBABILITY:\n",
    "                if self.add_noise_transform:\n",
    "                    wav = self.add_noise_transform(wav)\n",
    "\n",
    "        wav = self.pad_crop(wav)\n",
    "        wav = wav.squeeze(0)\n",
    "\n",
    "        if torch.isnan(wav).any():\n",
    "            print(f\"NaNs in wav for item {idx} AFTER processing, path: {full_wav_path}. Returning None.\")\n",
    "            return None\n",
    "\n",
    "        targets = {}\n",
    "        valid_item = True\n",
    "        for task_name, task_info in TASKS.items():\n",
    "            value = row[task_name]\n",
    "            if pd.isna(value):\n",
    "                print(f\"NaN target for task '{task_name}' at idx {idx}. Returning None.\")\n",
    "                valid_item = False\n",
    "                break\n",
    "\n",
    "            if task_info['type'] == 'regression':\n",
    "                mean = NORM_STATS[task_name]['mean']\n",
    "                std = NORM_STATS[task_name]['std']\n",
    "                norm_value = (value - mean) / (std if std > 1e-6 else 1.0)\n",
    "                targets[task_name] = torch.tensor(norm_value, dtype=torch.float32)\n",
    "            elif task_info['type'] == 'classification':\n",
    "                value_upper = str(value).upper()\n",
    "                mapping = GENDER_MAP\n",
    "                idx_value = mapping.get(value_upper, 0)\n",
    "                targets[task_name] = torch.tensor(idx_value, dtype=torch.long)\n",
    "\n",
    "        if not valid_item:\n",
    "            return None\n",
    "        return wav, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747128000964,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "_eGHz02AxFJk"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if not batch:\n",
    "        return None\n",
    "\n",
    "    wavs = [item[0] for item in batch]\n",
    "    target_dicts = [item[1] for item in batch]\n",
    "    padded_wavs = torch.nn.utils.rnn.pad_sequence(wavs, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    collated_targets = {}\n",
    "    if target_dicts:\n",
    "        first_item_keys = target_dicts[0].keys()\n",
    "        for key in first_item_keys:\n",
    "            if all(key in d for d in target_dicts):\n",
    "                 collated_targets[key] = torch.stack([d[key] for d in target_dicts])\n",
    "\n",
    "    if not collated_targets and target_dicts:\n",
    "         return None\n",
    "    return padded_wavs, collated_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1747128000976,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "Dj7QNo9IxIBI"
   },
   "outputs": [],
   "source": [
    "class sps_BiLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(PRETRAINED_W2V2)\n",
    "        self.wav2vec2_encoder = Wav2Vec2Model.from_pretrained(PRETRAINED_W2V2)\n",
    "\n",
    "        if FREEZE_ENCODER:\n",
    "            for param in self.wav2vec2_encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        encoder_output_dim = W2V2_OUTPUT_DIM\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=encoder_output_dim, hidden_size=LSTM_HIDDEN_SIZE,\n",
    "            num_layers=LSTM_NUM_LAYERS, batch_first=True,\n",
    "            bidirectional=True, dropout=MODEL_DROPOUT_RATE if LSTM_NUM_LAYERS > 1 else 0\n",
    "        )\n",
    "        bilstm_output_dim = LSTM_HIDDEN_SIZE * 2\n",
    "        self.heads = nn.ModuleDict()\n",
    "        head_common_input_dim = bilstm_output_dim\n",
    "\n",
    "        for task_name, task_info in TASKS.items():\n",
    "            head_specific_config = HEAD_CONFIGS[task_name]\n",
    "            head_hidden_dim = head_specific_config['head_hidden_dim']\n",
    "            head_dropout_rate = head_specific_config['head_dropout_rate']\n",
    "            output_dim = 1 if task_info['type'] == 'regression' else task_info.get('num_classes')\n",
    "            if output_dim is None and task_info['type'] == 'classification':\n",
    "                raise ValueError(f\"num_classes not set for classification task '{task_name}'\")\n",
    "\n",
    "            self.heads[task_name] = nn.Sequential(\n",
    "                nn.Linear(head_common_input_dim, head_hidden_dim), nn.ReLU(),\n",
    "                nn.Dropout(head_dropout_rate), nn.Linear(head_hidden_dim, output_dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        current_device = next(self.parameters()).device\n",
    "        waveform_list = [wav.cpu().numpy() for wav in waveform] if waveform.ndim == 2 else [waveform.cpu().numpy()]\n",
    "\n",
    "        inputs = self.feature_extractor(\n",
    "            waveform_list, sampling_rate=SAMPLE_RATE, return_tensors=\"pt\",\n",
    "            padding=\"longest\", return_attention_mask=True\n",
    "        )\n",
    "        inputs = {k: v.to(current_device) for k, v in inputs.items()}\n",
    "        attention_mask_input = inputs.get('attention_mask')\n",
    "        if attention_mask_input is None:\n",
    "            attention_mask_input = torch.ones(inputs['input_values'].shape[0], inputs['input_values'].shape[1], dtype=torch.long, device=current_device)\n",
    "\n",
    "        w2v2_outputs = self.wav2vec2_encoder(inputs['input_values'], attention_mask=attention_mask_input)\n",
    "        hidden_states = w2v2_outputs.last_hidden_state\n",
    "        bilstm_output, _ = self.bilstm(hidden_states)\n",
    "\n",
    "        actual_sequence_length = hidden_states.shape[1]\n",
    "        # Correct attention_mask_output slicing\n",
    "        if attention_mask_input.shape[1] >= actual_sequence_length:\n",
    "            attention_mask_output = attention_mask_input[:, :actual_sequence_length]\n",
    "        else: \n",
    "            attention_mask_output = torch.ones(hidden_states.shape[0], actual_sequence_length, device=current_device, dtype=torch.long)\n",
    "\n",
    "\n",
    "        expanded_attention_mask = attention_mask_output.unsqueeze(-1).expand_as(bilstm_output)\n",
    "        masked_bilstm_output = bilstm_output * expanded_attention_mask\n",
    "        summed_bilstm_output = torch.sum(masked_bilstm_output, dim=1)\n",
    "        valid_lengths = expanded_attention_mask.sum(dim=1).clamp(min=1e-9)\n",
    "        pooled_output = summed_bilstm_output / valid_lengths\n",
    "\n",
    "        predictions = {}\n",
    "        for task_name, head_module in self.heads.items():\n",
    "            task_prediction = head_module(pooled_output)\n",
    "            if TASKS[task_name]['type'] == 'regression':\n",
    "                predictions[task_name] = task_prediction.squeeze(-1)\n",
    "            else:\n",
    "                predictions[task_name] = task_prediction\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747128000991,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "nAffFBWLxKep",
    "outputId": "3dfd76cd-bc92-4062-cfd6-c1f6fd4e01da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "random.seed(VAL_SPLIT_SEED)\n",
    "np.random.seed(VAL_SPLIT_SEED)\n",
    "torch.manual_seed(VAL_SPLIT_SEED)\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.manual_seed_all(VAL_SPLIT_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1747128001017,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "GWufXkSJxKc0",
    "outputId": "76eb921b-d458-4518-bb7c-47624e85954c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw train data: 4490 rows, raw test data: 1640 rows\n"
     ]
    }
   ],
   "source": [
    "full_train_df_raw = pd.read_csv(TRAIN_CSV_PATH)\n",
    "test_df_raw = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "print(f\"Loaded raw train data: {len(full_train_df_raw)} rows, raw test data: {len(test_df_raw)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1747128001043,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "948u9O8oxKaz"
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['index', 'Use_x', 'DR', 'Ethnicity']\n",
    "\n",
    "full_train_df = full_train_df_raw.drop(columns=[col for col in cols_to_drop if col in full_train_df_raw.columns], errors='ignore')\n",
    "test_df = test_df_raw.drop(columns=[col for col in cols_to_drop if col in test_df_raw.columns], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1747128001047,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "5Hy2a567xOrp",
    "outputId": "ccb9f1f7-b4c8-4e0f-8c86-e4fc2b557413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train data: 4490 rows, Processed test data: 1640 rows\n"
     ]
    }
   ],
   "source": [
    "critical_cols = ['FilePath'] + list(TASKS.keys())\n",
    "full_train_df.dropna(subset=critical_cols, inplace=True)\n",
    "test_df.dropna(subset=critical_cols, inplace=True)\n",
    "full_train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Processed train data: {len(full_train_df)} rows, Processed test data: {len(test_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747128001050,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "GIM5YhlgxOp1",
    "outputId": "14d6a1d9-7a77-48b7-acc7-9dfb83caebfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating normalization stats and mappings...\n",
      "  Age stats: Mean=30.29, Std=7.77\n",
      "  Gender mapping: {'F': 0, 'M': 1}, Num Classes: 2\n",
      "  Height stats: Mean=175.75, Std=9.52\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating normalization stats and mappings...\")\n",
    "for task_name, task_info in TASKS.items():\n",
    "    if task_info['type'] == 'regression':\n",
    "        mean = full_train_df[task_name].astype(float).mean()\n",
    "        std = full_train_df[task_name].astype(float).std()\n",
    "        NORM_STATS[task_name]['mean'] = mean\n",
    "        NORM_STATS[task_name]['std'] = std if (np.isfinite(std) and std > 1e-6) else 1.0\n",
    "        print(f\"  {task_name.capitalize()} stats: Mean={NORM_STATS[task_name]['mean']:.2f}, Std={NORM_STATS[task_name]['std']:.2f}\")\n",
    "    elif task_info['type'] == 'classification':\n",
    "        if task_name == 'Gender':\n",
    "            cats = sorted(list(full_train_df[task_name].astype(str).str.upper().unique()))\n",
    "            TASKS[task_name]['num_classes'] = len(cats)\n",
    "            GENDER_MAP = {cat: i for i, cat in enumerate(cats)}\n",
    "            print(f\"  Gender mapping: {GENDER_MAP}, Num Classes: {TASKS[task_name]['num_classes']}\")\n",
    "        else:\n",
    "             unique_values = full_train_df[task_name].unique()\n",
    "             TASKS[task_name]['num_classes'] = len(unique_values)\n",
    "             print(f\"  {task_name.capitalize()} Num Classes: {TASKS[task_name]['num_classes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747128001053,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "GftHjN_TxOnS",
    "outputId": "2ebea584-55e6-454d-ec4a-b3ff1a770dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data by SpeakerID...\n",
      "Data split: Train=3140, Val=1350, Test=1640\n"
     ]
    }
   ],
   "source": [
    "if 'SpeakerID' in full_train_df.columns:\n",
    "    print(\"Splitting data by SpeakerID...\")\n",
    "    speaker_ids = full_train_df['SpeakerID'].unique()\n",
    "    train_spk_ids, val_spk_ids = train_test_split(speaker_ids, test_size=VAL_SPLIT_RATIO, random_state=VAL_SPLIT_SEED)\n",
    "    train_df = full_train_df[full_train_df['SpeakerID'].isin(train_spk_ids)].copy()\n",
    "    val_df = full_train_df[full_train_df['SpeakerID'].isin(val_spk_ids)].copy()\n",
    "else:\n",
    "    print(\"Warning: 'SpeakerID' not found. Performing random split.\")\n",
    "    train_df, val_df = train_test_split(full_train_df, test_size=VAL_SPLIT_RATIO, random_state=VAL_SPLIT_SEED)\n",
    "print(f\"Data split: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747128001054,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "RW_19hN5xVb_"
   },
   "outputs": [],
   "source": [
    "train_dataset = TimitDataset(train_df, mode='train')\n",
    "val_dataset = TimitDataset(val_df, mode='eval')\n",
    "test_dataset = TimitDataset(test_df, mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747128001055,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "rEN-HaZIxW3Y"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, collate_fn=collate_fn, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1671,
     "status": "ok",
     "timestamp": 1747128002733,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "YWnNFBFTxYhY"
   },
   "outputs": [],
   "source": [
    "model = sps_BiLSTM().to(DEVICE)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747128002735,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "WL5OuaIkxZoM"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE, weight_decay=OPTIMIZER_WEIGHT_DECAY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1747128002736,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "1gyQNJe2xdAI"
   },
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "criterion_cls = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747128002745,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "QHfRBoqcxe2k"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=MONITOR_METRIC_MODE, factor=LR_SCHEDULER_FACTOR,\n",
    "    patience=LR_SCHEDULER_PATIENCE, min_lr=MIN_LR, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747128002748,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "gGABTgijxhvx"
   },
   "outputs": [],
   "source": [
    "def validate_epoch(val_loader, model, device):\n",
    "    model.eval()\n",
    "    running_task_losses_val = {task: 0.0 for task in TASKS}\n",
    "    num_samples_val = 0\n",
    "    all_targets_val = {task: [] for task in TASKS}\n",
    "    all_preds_val = {task: [] for task in TASKS}\n",
    "\n",
    "    criterion_reg_val = nn.MSELoss(reduction='sum')\n",
    "    criterion_cls_val = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(val_loader):\n",
    "            if batch_data is None: continue\n",
    "            wav, targets = batch_data\n",
    "            if wav.numel() == 0 or not targets: continue\n",
    "\n",
    "            wav = wav.to(device)\n",
    "            targets = {k: v.to(device) for k, v in targets.items()}\n",
    "            current_batch_size = wav.size(0)\n",
    "\n",
    "            predictions = model(wav)\n",
    "            valid_batch = True\n",
    "            for task_name, task_info in TASKS.items():\n",
    "                if task_name not in predictions or task_name not in targets:\n",
    "                    print(f\"Warning: Missing pred/target for task '{task_name}' in val batch {batch_idx}\")\n",
    "                    valid_batch = False\n",
    "                    break\n",
    "                pred_val = predictions[task_name]\n",
    "                target_val = targets[task_name]\n",
    "                if task_info['type'] == 'regression' and pred_val.shape != target_val.shape:\n",
    "                    target_val = target_val.view_as(pred_val)\n",
    "\n",
    "                loss_val = criterion_reg_val(pred_val, target_val) if task_info['type'] == 'regression' \\\n",
    "                           else criterion_cls_val(pred_val, target_val)\n",
    "\n",
    "                if torch.isnan(loss_val) or torch.isinf(loss_val):\n",
    "                    print(f\"NaN/Inf val loss for task {task_name}, batch {batch_idx}. Setting to high value.\")\n",
    "                    running_task_losses_val[task_name] += 1e9 * current_batch_size\n",
    "                    valid_batch = False\n",
    "                    break\n",
    "                else:\n",
    "                    running_task_losses_val[task_name] += loss_val.item()\n",
    "            if not valid_batch:\n",
    "              continue\n",
    "\n",
    "            num_samples_val += current_batch_size\n",
    "\n",
    "    avg_task_losses_val = {}\n",
    "    weighted_val_loss = 0.0\n",
    "    if num_samples_val > 0:\n",
    "        for task_name in TASKS.keys():\n",
    "            avg_loss = running_task_losses_val[task_name] / num_samples_val\n",
    "            avg_task_losses_val[task_name] = avg_loss\n",
    "            if task_name in EVAL_LOSS_WEIGHTS:\n",
    "                 weighted_val_loss += EVAL_LOSS_WEIGHTS[task_name] * avg_loss\n",
    "    else:\n",
    "        for task_name in TASKS.keys(): avg_task_losses_val[task_name] = float('inf')\n",
    "        weighted_val_loss = float('inf')\n",
    "\n",
    "    return avg_task_losses_val, weighted_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1447635,
     "status": "ok",
     "timestamp": 1747129450384,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "rJPdzQLHxluN",
    "outputId": "24328f91-fb4c-4652-f43c-2370ccbe06ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "Epoch 1 Summary: Avg Train Loss: 0.8179 | Avg age TrL: 0.9346 | Avg Gen TrL: 0.6097 | Avg hei TrL: 1.0008\n",
      "Epoch 1 Validation: Weighted Val Loss: 0.9058 | Avg age VaL: 1.1623 | Avg Gen VaL: 0.6241 | Avg hei VaL: 1.0197\n",
      "  Best model saved! Epoch 1, Val Metric: 0.9058\n",
      "Epoch 2 Summary: Avg Train Loss: 0.8117 | Avg age TrL: 0.9294 | Avg Gen TrL: 0.5994 | Avg hei TrL: 1.0008\n",
      "Epoch 2 Validation: Weighted Val Loss: 0.9117 | Avg age VaL: 1.1704 | Avg Gen VaL: 0.6322 | Avg hei VaL: 1.0053\n",
      "  No improvement in val metric for 1 epoch(s). Best: 0.9058\n",
      "Epoch 3 Summary: Avg Train Loss: 0.8121 | Avg age TrL: 0.9310 | Avg Gen TrL: 0.6000 | Avg hei TrL: 0.9987\n",
      "Epoch 3 Validation: Weighted Val Loss: 0.9107 | Avg age VaL: 1.1665 | Avg Gen VaL: 0.6339 | Avg hei VaL: 1.0050\n",
      "  No improvement in val metric for 2 epoch(s). Best: 0.9058\n",
      "Epoch 4 Summary: Avg Train Loss: 0.8125 | Avg age TrL: 0.9287 | Avg Gen TrL: 0.6025 | Avg hei TrL: 0.9999\n",
      "Epoch 4 Validation: Weighted Val Loss: 0.9065 | Avg age VaL: 1.1701 | Avg Gen VaL: 0.6204 | Avg hei VaL: 1.0075\n",
      "  No improvement in val metric for 3 epoch(s). Best: 0.9058\n",
      "Epoch 5 Summary: Avg Train Loss: 0.8094 | Avg age TrL: 0.9259 | Avg Gen TrL: 0.5976 | Avg hei TrL: 0.9999\n",
      "Epoch 5 Validation: Weighted Val Loss: 0.9082 | Avg age VaL: 1.1726 | Avg Gen VaL: 0.6219 | Avg hei VaL: 1.0068\n",
      "  No improvement in val metric for 4 epoch(s). Best: 0.9058\n",
      "Epoch 6 Summary: Avg Train Loss: 0.8104 | Avg age TrL: 0.9284 | Avg Gen TrL: 0.5979 | Avg hei TrL: 0.9994\n",
      "Epoch 6 Validation: Weighted Val Loss: 0.9069 | Avg age VaL: 1.1705 | Avg Gen VaL: 0.6211 | Avg hei VaL: 1.0071\n",
      "  No improvement in val metric for 5 epoch(s). Best: 0.9058\n",
      "Epoch 7 Summary: Avg Train Loss: 0.8100 | Avg age TrL: 0.9270 | Avg Gen TrL: 0.5991 | Avg hei TrL: 0.9979\n",
      "Epoch 7 Validation: Weighted Val Loss: 0.9047 | Avg age VaL: 1.1669 | Avg Gen VaL: 0.6201 | Avg hei VaL: 1.0059\n",
      "  Best model saved! Epoch 7, Val Metric: 0.9047\n",
      "Epoch 8 Summary: Avg Train Loss: 0.8115 | Avg age TrL: 0.9286 | Avg Gen TrL: 0.6004 | Avg hei TrL: 0.9994\n",
      "Epoch 8 Validation: Weighted Val Loss: 0.9074 | Avg age VaL: 1.1713 | Avg Gen VaL: 0.6215 | Avg hei VaL: 1.0066\n",
      "  No improvement in val metric for 1 epoch(s). Best: 0.9047\n",
      "Epoch 9 Summary: Avg Train Loss: 0.8111 | Avg age TrL: 0.9283 | Avg Gen TrL: 0.6003 | Avg hei TrL: 0.9985\n",
      "Epoch 9 Validation: Weighted Val Loss: 0.9133 | Avg age VaL: 1.1771 | Avg Gen VaL: 0.6287 | Avg hei VaL: 1.0070\n",
      "  No improvement in val metric for 2 epoch(s). Best: 0.9047\n",
      "Epoch 10 Summary: Avg Train Loss: 0.8108 | Avg age TrL: 0.9285 | Avg Gen TrL: 0.5991 | Avg hei TrL: 0.9989\n",
      "Epoch 10 Validation: Weighted Val Loss: 0.9094 | Avg age VaL: 1.1771 | Avg Gen VaL: 0.6201 | Avg hei VaL: 1.0068\n",
      "  No improvement in val metric for 3 epoch(s). Best: 0.9047\n",
      "Epoch 11 Summary: Avg Train Loss: 0.8109 | Avg age TrL: 0.9291 | Avg Gen TrL: 0.5982 | Avg hei TrL: 0.9997\n",
      "Epoch 11 Validation: Weighted Val Loss: 0.9077 | Avg age VaL: 1.1706 | Avg Gen VaL: 0.6227 | Avg hei VaL: 1.0070\n",
      "  No improvement in val metric for 4 epoch(s). Best: 0.9047\n",
      "Epoch 12 Summary: Avg Train Loss: 0.8089 | Avg age TrL: 0.9288 | Avg Gen TrL: 0.5954 | Avg hei TrL: 0.9961\n",
      "Epoch 12 Validation: Weighted Val Loss: 0.9121 | Avg age VaL: 1.1743 | Avg Gen VaL: 0.6287 | Avg hei VaL: 1.0073\n",
      "  No improvement in val metric for 5 epoch(s). Best: 0.9047\n",
      "Epoch 13 Summary: Avg Train Loss: 0.8090 | Avg age TrL: 0.9246 | Avg Gen TrL: 0.5979 | Avg hei TrL: 0.9998\n",
      "Epoch 13 Validation: Weighted Val Loss: 0.9071 | Avg age VaL: 1.1718 | Avg Gen VaL: 0.6202 | Avg hei VaL: 1.0075\n",
      "  No improvement in val metric for 6 epoch(s). Best: 0.9047\n",
      "Epoch 14 Summary: Avg Train Loss: 0.8105 | Avg age TrL: 0.9281 | Avg Gen TrL: 0.5987 | Avg hei TrL: 0.9987\n",
      "Epoch 14 Validation: Weighted Val Loss: 0.9075 | Avg age VaL: 1.1721 | Avg Gen VaL: 0.6206 | Avg hei VaL: 1.0076\n",
      "  No improvement in val metric for 7 epoch(s). Best: 0.9047\n",
      "Epoch 15 Summary: Avg Train Loss: 0.8096 | Avg age TrL: 0.9260 | Avg Gen TrL: 0.5980 | Avg hei TrL: 1.0003\n",
      "Epoch 15 Validation: Weighted Val Loss: 0.9077 | Avg age VaL: 1.1721 | Avg Gen VaL: 0.6211 | Avg hei VaL: 1.0075\n",
      "  No improvement in val metric for 8 epoch(s). Best: 0.9047\n",
      "Epoch 16 Summary: Avg Train Loss: 0.8088 | Avg age TrL: 0.9265 | Avg Gen TrL: 0.5958 | Avg hei TrL: 0.9997\n",
      "Epoch 16 Validation: Weighted Val Loss: 0.9082 | Avg age VaL: 1.1723 | Avg Gen VaL: 0.6220 | Avg hei VaL: 1.0076\n",
      "  No improvement in val metric for 9 epoch(s). Best: 0.9047\n",
      "Epoch 17 Summary: Avg Train Loss: 0.8091 | Avg age TrL: 0.9267 | Avg Gen TrL: 0.5964 | Avg hei TrL: 0.9994\n",
      "Epoch 17 Validation: Weighted Val Loss: 0.9079 | Avg age VaL: 1.1722 | Avg Gen VaL: 0.6214 | Avg hei VaL: 1.0074\n",
      "  No improvement in val metric for 10 epoch(s). Best: 0.9047\n",
      "Epoch 18 Summary: Avg Train Loss: 0.8099 | Avg age TrL: 0.9278 | Avg Gen TrL: 0.5973 | Avg hei TrL: 0.9993\n",
      "Epoch 18 Validation: Weighted Val Loss: 0.9077 | Avg age VaL: 1.1717 | Avg Gen VaL: 0.6215 | Avg hei VaL: 1.0075\n",
      "  No improvement in val metric for 11 epoch(s). Best: 0.9047\n",
      "Epoch 19 Summary: Avg Train Loss: 0.8095 | Avg age TrL: 0.9285 | Avg Gen TrL: 0.5963 | Avg hei TrL: 0.9978\n",
      "Epoch 19 Validation: Weighted Val Loss: 0.9071 | Avg age VaL: 1.1711 | Avg Gen VaL: 0.6208 | Avg hei VaL: 1.0074\n",
      "  No improvement in val metric for 12 epoch(s). Best: 0.9047\n",
      "Epoch 20 Summary: Avg Train Loss: 0.8104 | Avg age TrL: 0.9285 | Avg Gen TrL: 0.5978 | Avg hei TrL: 0.9996\n",
      "Epoch 20 Validation: Weighted Val Loss: 0.9075 | Avg age VaL: 1.1715 | Avg Gen VaL: 0.6212 | Avg hei VaL: 1.0074\n",
      "  No improvement in val metric for 13 epoch(s). Best: 0.9047\n",
      "Epoch 21 Summary: Avg Train Loss: 0.8089 | Avg age TrL: 0.9272 | Avg Gen TrL: 0.5956 | Avg hei TrL: 0.9989\n",
      "Epoch 21 Validation: Weighted Val Loss: 0.9078 | Avg age VaL: 1.1712 | Avg Gen VaL: 0.6222 | Avg hei VaL: 1.0077\n",
      "  No improvement in val metric for 14 epoch(s). Best: 0.9047\n",
      "Epoch 22 Summary: Avg Train Loss: 0.8050 | Avg age TrL: 0.9174 | Avg Gen TrL: 0.5964 | Avg hei TrL: 0.9974\n",
      "Epoch 22 Validation: Weighted Val Loss: 0.9079 | Avg age VaL: 1.1712 | Avg Gen VaL: 0.6224 | Avg hei VaL: 1.0079\n",
      "  No improvement in val metric for 15 epoch(s). Best: 0.9047\n",
      "Early stopping triggered after 22 epochs due to no improvement for 15 epochs.\n",
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting Training ---\")\n",
    "best_val_metric = float('inf') if MONITOR_METRIC_MODE == 'min' else float('-inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss_epoch = 0.0\n",
    "    task_losses_epoch = {task: 0.0 for task in TASKS}\n",
    "    num_samples_processed = 0\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        if batch_data is None: continue\n",
    "        wav, targets = batch_data\n",
    "        if wav.numel() == 0 or not targets:\n",
    "          continue\n",
    "\n",
    "        wav = wav.to(DEVICE)\n",
    "        targets = {k: v.to(DEVICE) for k, v in targets.items()}\n",
    "        current_batch_size = wav.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(wav)\n",
    "        combined_loss_batch = torch.tensor(0.0, device=DEVICE)\n",
    "        current_batch_task_losses = {}\n",
    "        valid_batch_for_loss = True\n",
    "\n",
    "        for task_name, task_info in TASKS.items():\n",
    "            if task_name not in predictions or task_name not in targets:\n",
    "                 valid_batch_for_loss = False\n",
    "                 break\n",
    "            pred = predictions[task_name]\n",
    "            target = targets[task_name]\n",
    "            if task_info['type'] == 'regression' and pred.shape != target.shape:\n",
    "                target = target.view_as(pred)\n",
    "            loss = criterion_reg(pred, target) if task_info['type'] == 'regression' else criterion_cls(pred, target)\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"NaN/Inf train loss for task {task_name}, batch {batch_idx+1}. Skipping batch update.\")\n",
    "                valid_batch_for_loss = False\n",
    "                break\n",
    "            combined_loss_batch += task_info['loss_weight'] * loss\n",
    "            current_batch_task_losses[task_name] = loss.item()\n",
    "\n",
    "        if valid_batch_for_loss:\n",
    "            combined_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            total_loss_epoch += combined_loss_batch.item() * current_batch_size\n",
    "            for task_name, loss_item in current_batch_task_losses.items():\n",
    "                task_losses_epoch[task_name] += loss_item * current_batch_size\n",
    "            num_samples_processed += current_batch_size\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                 loss_str = \" | \".join([f\"{k[:3]}L: {v:.3f}\" for k,v in current_batch_task_losses.items()])\n",
    "                #  print(f\"  Epoch {epoch}/{EPOCHS} | Batch {batch_idx+1}/{len(train_loader)} | Batch Loss: {combined_loss_batch.item():.4f} | {loss_str}\")\n",
    "\n",
    "    avg_loss_epoch = total_loss_epoch / num_samples_processed if num_samples_processed > 0 else float('inf')\n",
    "    avg_task_train_losses_epoch = {k: v / num_samples_processed if num_samples_processed > 0 else float('inf') for k, v in task_losses_epoch.items()}\n",
    "    train_loss_str = \" | \".join([f\"Avg {k[:3]} TrL: {v:.4f}\" for k, v in avg_task_train_losses_epoch.items()])\n",
    "    print(f\"Epoch {epoch} Summary: Avg Train Loss: {avg_loss_epoch:.4f} | {train_loss_str}\")\n",
    "\n",
    "    # Validation\n",
    "    if len(val_loader) > 0:\n",
    "        avg_task_val_losses, current_val_metric = validate_epoch(val_loader, model, DEVICE)\n",
    "        val_loss_str = \" | \".join([f\"Avg {k[:3]} VaL: {v:.4f}\" for k,v in avg_task_val_losses.items()])\n",
    "        print(f\"Epoch {epoch} Validation: Weighted Val Loss: {current_val_metric:.4f} | {val_loss_str}\")\n",
    "\n",
    "        scheduler.step(current_val_metric)\n",
    "\n",
    "        # Save Best Model\n",
    "        if (MONITOR_METRIC_MODE == 'min' and current_val_metric < best_val_metric) or \\\n",
    "           (MONITOR_METRIC_MODE == 'max' and current_val_metric > best_val_metric):\n",
    "            best_val_metric = current_val_metric\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_state, CKPT_PATH)\n",
    "            print(f\"  Best model saved! Epoch {epoch}, Val Metric: {best_val_metric:.4f}\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  No improvement in val metric for {epochs_no_improve} epoch(s). Best: {best_val_metric:.4f}\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs due to no improvement for {EARLY_STOPPING_PATIENCE} epochs.\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Skipping validation as val_loader is empty.\")\n",
    "\n",
    "print(\"--- Training Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13965,
     "status": "ok",
     "timestamp": 1747129464352,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "oZUWZCEtxoe_",
    "outputId": "1731a93f-b671-4017-92ad-b7351f2d8605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating on Test Set with Best Model ---\n",
      "Loading best model from memory (Val Metric: 0.9047) for final test.\n",
      "  Evaluated test batch 20/52\n",
      "  Evaluated test batch 40/52\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating on Test Set with Best Model ---\")\n",
    "if best_model_state is not None:\n",
    "    print(f\"Loading best model from memory (Val Metric: {best_val_metric:.4f}) for final test.\")\n",
    "    model.load_state_dict(best_model_state)\n",
    "elif os.path.exists(CKPT_PATH): \n",
    "    print(f\"Loading best model from checkpoint: {CKPT_PATH}\")\n",
    "    model.load_state_dict(torch.load(CKPT_PATH, map_location=DEVICE))\n",
    "else:\n",
    "    print(\"No best model state found. Evaluating with the last model state.\")\n",
    "\n",
    "model.eval()\n",
    "all_targets_test = {task: [] for task in TASKS}\n",
    "all_preds_test = {task: [] for task in TASKS}\n",
    "running_task_losses_test = {task: 0.0 for task in TASKS}\n",
    "num_samples_test = 0\n",
    "\n",
    "criterion_reg_test = nn.MSELoss(reduction='sum')\n",
    "criterion_cls_test = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch_data in enumerate(test_loader):\n",
    "        if batch_data is None: continue\n",
    "        wav, targets = batch_data\n",
    "        if wav.numel() == 0 or not targets: continue\n",
    "\n",
    "        wav = wav.to(DEVICE)\n",
    "        targets_device = {k: v.to(DEVICE) for k, v in targets.items()}\n",
    "        current_batch_size = wav.size(0)\n",
    "        predictions = model(wav)\n",
    "\n",
    "        for task_name, task_info in TASKS.items():\n",
    "            if task_name not in predictions or task_name not in targets_device: continue\n",
    "            pred_val = predictions[task_name]\n",
    "            target_val = targets_device[task_name]\n",
    "            if task_info['type'] == 'regression' and pred_val.shape != target_val.shape:\n",
    "                target_val = target_val.view_as(pred_val)\n",
    "\n",
    "            loss_val = criterion_reg_test(pred_val, target_val) if task_info['type'] == 'regression' \\\n",
    "                       else criterion_cls_test(pred_val, target_val)\n",
    "            running_task_losses_test[task_name] += loss_val.item()\n",
    "\n",
    "            pred_cpu = pred_val.cpu()\n",
    "            target_cpu = targets[task_name] \n",
    "            if task_info['type'] == 'regression':\n",
    "                mean, std = NORM_STATS[task_name]['mean'], NORM_STATS[task_name]['std']\n",
    "                pred_denorm = (pred_cpu * (std if std > 1e-6 else 1.0)) + mean\n",
    "                target_denorm = (target_cpu * (std if std > 1e-6 else 1.0)) + mean\n",
    "                all_preds_test[task_name].extend(pred_denorm.tolist())\n",
    "                all_targets_test[task_name].extend(target_denorm.tolist())\n",
    "            else:\n",
    "                pred_labels = torch.argmax(pred_cpu, dim=1)\n",
    "                all_preds_test[task_name].extend(pred_labels.tolist())\n",
    "                all_targets_test[task_name].extend(target_cpu.tolist())\n",
    "        num_samples_test += current_batch_size\n",
    "        if (batch_idx + 1) % 20 == 0: print(f\"  Evaluated test batch {batch_idx+1}/{len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1747129464373,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "A88aWHQtj2Em",
    "outputId": "21ae89f1-8b7e-4f28-e019-0ef052efa94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Test Results (Best Model) ---\n",
      "  Test MSE (age): 72.5292 (RMSE: 8.5164)\n",
      "  Test Accuracy (Gender): 0.6585\n",
      "  Test MSE (height): 82.7372 (RMSE: 9.0960)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics_test = {}\n",
    "avg_task_losses_test = {}\n",
    "print(\"\\n--- Final Test Results (Best Model) ---\")\n",
    "if num_samples_test > 0:\n",
    "    for task_name, task_info in TASKS.items():\n",
    "        avg_task_losses_test[task_name] = running_task_losses_test[task_name] / \\\n",
    "            num_samples_test\n",
    "        # print(f\"  Avg Test Loss ({task_name}): {avg_task_losses_test[task_name]:.4f}\")\n",
    "        targets_np = np.array(all_targets_test[task_name])\n",
    "        preds_np = np.array(all_preds_test[task_name])\n",
    "        if len(targets_np) > 0 and len(targets_np) == len(preds_np):\n",
    "            if task_info['type'] == 'regression':\n",
    "                mse = mean_squared_error(targets_np, preds_np)\n",
    "                metrics_test[f\"{task_name}_mse\"] = mse\n",
    "                print(\n",
    "                    f\"  Test MSE ({task_name}): {mse:.4f} (RMSE: {np.sqrt(mse):.4f})\")\n",
    "            else:\n",
    "                acc = accuracy_score(targets_np, preds_np)\n",
    "                metrics_test[f\"{task_name}_acc\"] = acc\n",
    "                print(f\"  Test Accuracy ({task_name}): {acc:.4f}\")\n",
    "        else:\n",
    "            metric_key = f\"{task_name}_{'mse' if task_info['type'] == 'regression' else 'acc'}\"\n",
    "            metrics_test[metric_key] = float('nan')\n",
    "            print(\n",
    "                f\"  Could not calculate metric for {task_name} (data issue).\")\n",
    "else:\n",
    "    print(\"No samples processed during final test evaluation.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqZ8DmzK7_iK"
   },
   "source": [
    "\n",
    "--- Final Test Results (Best Model) --- 2 layers BiLSTM\n",
    "  * Test MSE (age): 72.5123 (RMSE: 8.5154)\n",
    "  * Test Accuracy (Gender): 0.6585\n",
    "  * Test MSE (height): 82.8730 (RMSE: 9.1035)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6C67eLtYw4ln"
   },
   "source": [
    "\n",
    "--- Final Test Results --- 3 layers BiLSTM\n",
    " * Test MSE (age): 73.1914 (RMSE: 8.5551)\n",
    " * Test Accuracy (Gender): 0.6585\n",
    " * Test MSE (height): 80.2048 (RMSE: 8.9557)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Final Test Results (Best Model) --- 4 layers BiLSTM\n",
    "  * Test MSE (age): 72.5292 (RMSE: 8.5164)\n",
    "  * Test Accuracy (Gender): 0.6585\n",
    "  * Test MSE (height): 82.7372 (RMSE: 9.0960)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOu2MYr758cOmvHcZHWvwQ5",
   "gpuType": "L4",
   "mount_file_id": "1Xs-gkhIDycZeINM6lsb6w1MZteJfkdPI",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

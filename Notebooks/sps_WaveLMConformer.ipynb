{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747136691564,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "FksZ383M-epb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1542354,
     "status": "ok",
     "timestamp": 1747138233920,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "rPamFVCG-ebl",
    "outputId": "068a12e8-d29c-4766-daa3-81c2adace26c"
   },
   "outputs": [],
   "source": [
    "# !mkdir 'timit_dataset'\n",
    "# !unzip '/content/drive/MyDrive/sps/preprocessed_timit_dataset.zip' -d timit_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1747138233940,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "Vs1JH_hy-eZD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from transformers import WavLMModel, Wav2Vec2FeatureExtractor\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747138233948,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "y4C0VopDLUdU"
   },
   "outputs": [],
   "source": [
    "AUDIO_ROOT_DIR = '/content/timit_dataset'\n",
    "DRIVE_PATH = '/content/drive/MyDrive/sps/'\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(DRIVE_PATH, 'final_train_data_merged.csv')\n",
    "TEST_CSV_PATH = os.path.join(DRIVE_PATH, 'final_test_data_merged.csv')\n",
    "CKPT_PATH = os.path.join(DRIVE_PATH, 'sps_wavlm_conformer_best_model.pth')\n",
    "\n",
    "# Audio Processing\n",
    "SAMPLE_RATE = 16000\n",
    "CLIP_SECONDS = 4.0\n",
    "WAV_LEN = int(SAMPLE_RATE * CLIP_SECONDS)\n",
    "\n",
    "# Audio Augmentations\n",
    "APPLY_AUGMENTATIONS = True\n",
    "AUGMENTATION_PROBABILITY = 0.3\n",
    "ADD_NOISE_PROBABILITY = 0.3\n",
    "NOISE_SNR_MIN = 7.0\n",
    "NOISE_SNR_MAX = 25.0\n",
    "\n",
    "# WavLM\n",
    "PRETRAINED_SSL_MODEL = 'microsoft/wavlm-base-plus'\n",
    "SSL_OUTPUT_DIM = 768\n",
    "FINETUNE_SSL_MODEL = True\n",
    "FINETUNE_SSL_LAYERS = 2\n",
    "\n",
    "# Conformer Encoder Parameters\n",
    "CONFORMER_INPUT_DIM = SSL_OUTPUT_DIM\n",
    "CONFORMER_NUM_BLOCKS = 4\n",
    "CONFORMER_FF_DIM_FACTOR = 4\n",
    "CONFORMER_NHEAD = 8\n",
    "CONFORMER_CONV_KERNEL_SIZE = 31\n",
    "CONFORMER_DROPOUT = 0.1\n",
    "\n",
    "# Attentive Statistics Pooling Parameters\n",
    "ATTN_POOL_DIM = 128\n",
    "\n",
    "# Shared Dropout\n",
    "MODEL_DROPOUT_RATE = 0.3\n",
    "\n",
    "# Training Hyperparameters\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-5\n",
    "SSL_FINETUNE_LR_FACTOR = 0.1\n",
    "OPTIMIZER_WEIGHT_DECAY = 0.01\n",
    "GRADIENT_CLIP_MAX_NORM = 1.0\n",
    "LR_WARMUP_EPOCHS = 5\n",
    "\n",
    "# Validation\n",
    "VAL_SPLIT_RATIO = 0.25\n",
    "VAL_SPLIT_SEED = 42\n",
    "\n",
    "# Task Configuration\n",
    "TASKS = {\n",
    "    'age': {'type': 'regression', 'loss_weight': 0.4},\n",
    "    'Gender': {'type': 'classification', 'loss_weight': 0.3},\n",
    "    'height': {'type': 'regression', 'loss_weight': 0.3}\n",
    "}\n",
    "\n",
    "# Head-Specific Hyperparameters\n",
    "HEAD_CONFIGS = {\n",
    "    'age': {'head_hidden_dim': 128, 'head_dropout_rate': 0.25},\n",
    "    'Gender': {'head_hidden_dim': 96, 'head_dropout_rate': 0.25},\n",
    "    'height': {'head_hidden_dim': 64, 'head_dropout_rate': 0.2}\n",
    "}\n",
    "\n",
    "# Mappings and Normalization Stats\n",
    "GENDER_MAP = {}\n",
    "NORM_STATS = {'age': {'mean': 0.0, 'std': 1.0},\n",
    "              'height': {'mean': 0.0, 'std': 1.0}}\n",
    "\n",
    "# DataLoader\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True if DEVICE == 'cuda' else False\n",
    "\n",
    "# Model Saving, Early Stopping, LR Scheduling\n",
    "MONITOR_METRIC_MODE = 'min'\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "LR_SCHEDULER_PATIENCE = 7\n",
    "LR_SCHEDULER_FACTOR = 0.2\n",
    "MIN_LR = 1e-7\n",
    "\n",
    "EVAL_LOSS_WEIGHTS = {'age': 0.4, 'Gender': 0.4, 'height': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747142211069,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "9WYHbZqaLpw0"
   },
   "outputs": [],
   "source": [
    "class PadCrop:\n",
    "    def __init__(self, length: int, mode: str = 'train'):\n",
    "        self.length = length\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, wav: torch.Tensor):\n",
    "        current_len = wav.shape[-1]\n",
    "        if current_len == self.length:\n",
    "          return wav\n",
    "\n",
    "        elif current_len > self.length:\n",
    "            start = random.randint(0, current_len - self.length) if self.mode == 'train' else (current_len - self.length) // 2\n",
    "            wav = wav[..., start : start + self.length]\n",
    "\n",
    "        else:\n",
    "            pad_width = self.length - current_len\n",
    "            pad_left = pad_width // 2\n",
    "            pad_right = pad_width - pad_left\n",
    "            wav = F.pad(wav, (pad_left, pad_right), mode='constant', value=0.0)\n",
    "\n",
    "        return wav\n",
    "\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, min_snr_db: float = 5.0, max_snr_db: float = 20.0, p: float = 0.5):\n",
    "        self.min_snr_db = min_snr_db\n",
    "        self.max_snr_db = max_snr_db\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, waveform: torch.Tensor):\n",
    "        if random.random() < self.p:\n",
    "            if waveform.ndim > 1 and waveform.shape[0] > 1:\n",
    "              wav_data_for_power_calc = waveform[0,:]\n",
    "\n",
    "            elif waveform.ndim > 1 and waveform.shape[0] == 1:\n",
    "              wav_data_for_power_calc = waveform.squeeze(0)\n",
    "\n",
    "            elif waveform.ndim == 1:\n",
    "              wav_data_for_power_calc = waveform\n",
    "            else:\n",
    "              return waveform\n",
    "\n",
    "            signal_power = torch.mean(wav_data_for_power_calc**2)\n",
    "            if signal_power.item() < 1e-9:\n",
    "              return waveform\n",
    "\n",
    "            snr_db = random.uniform(self.min_snr_db, self.max_snr_db)\n",
    "            snr_linear = 10**(snr_db / 10.0)\n",
    "            noise_power = signal_power / snr_linear\n",
    "            noise = torch.randn_like(waveform) * torch.sqrt(noise_power)\n",
    "            return waveform + noise\n",
    "        return waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747142214375,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "IO_AaQtsynG-"
   },
   "outputs": [],
   "source": [
    "class TimitDataset(Dataset):\n",
    "    def __init__(self, data_df: pd.DataFrame, mode: str = 'train'):\n",
    "        self.data_df = data_df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.pad_crop = PadCrop(WAV_LEN, mode)\n",
    "        self.target_cols = list(TASKS.keys())\n",
    "        self.add_noise_transform = None\n",
    "        if self.mode == 'train' and APPLY_AUGMENTATIONS:\n",
    "            self.add_noise_transform = AddGaussianNoise(NOISE_SNR_MIN, NOISE_SNR_MAX, ADD_NOISE_PROBABILITY)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if idx >= len(self.data_df): \n",
    "            print(f\"Index {idx} out of bounds...\")\n",
    "            return None\n",
    "        row = self.data_df.iloc[idx]\n",
    "        wav_relative_path = row['FilePath']\n",
    "        full_wav_path = os.path.normpath(os.path.join(AUDIO_ROOT_DIR, wav_relative_path))\n",
    "        wav, sr = torchaudio.load(full_wav_path)\n",
    "        if sr != SAMPLE_RATE: \n",
    "            wav = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(wav)\n",
    "        if wav.shape[0] > 1: \n",
    "            wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "        if self.mode == 'train' and APPLY_AUGMENTATIONS and random.random() < AUGMENTATION_PROBABILITY:\n",
    "            if self.add_noise_transform: wav = self.add_noise_transform(wav)\n",
    "        wav = self.pad_crop(wav).squeeze(0)\n",
    "        if torch.isnan(wav).any(): \n",
    "            print(f\"NaNs in wav {idx}.\")\n",
    "            return None\n",
    "\n",
    "        targets = {}\n",
    "        valid_item = True\n",
    "        for task_name, task_info in TASKS.items():\n",
    "            value = row[task_name]\n",
    "            if pd.isna(value): \n",
    "                print(f\"NaN target {task_name} at {idx}.\")\n",
    "                valid_item = False \n",
    "                break\n",
    "            if task_info['type'] == 'regression':\n",
    "                mean, std = NORM_STATS[task_name]['mean'], NORM_STATS[task_name]['std']\n",
    "                targets[task_name] = torch.tensor((value - mean) / (std if std > 1e-6 else 1.0), dtype=torch.float32)\n",
    "            elif task_info['type'] == 'classification':\n",
    "                targets[task_name] = torch.tensor(GENDER_MAP.get(str(value).upper(), 0), dtype=torch.long)\n",
    "                \n",
    "        return (wav, targets) if valid_item else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747138233952,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "sXIccJUhLsqg"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch: list):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "\n",
    "    if not batch:\n",
    "      return None\n",
    "\n",
    "    wavs = [item[0] for item in batch]\n",
    "    target_dicts = [item[1] for item in batch]\n",
    "    padded_wavs = torch.nn.utils.rnn.pad_sequence(wavs, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    collated_targets = {}\n",
    "    if target_dicts:\n",
    "        first_item_keys = target_dicts[0].keys()\n",
    "        for key in first_item_keys:\n",
    "            if all(key in d for d in target_dicts):\n",
    "                 collated_targets[key] = torch.stack([d[key] for d in target_dicts])\n",
    "\n",
    "    if not collated_targets and target_dicts:\n",
    "      return None\n",
    "\n",
    "    return padded_wavs, collated_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1747138233984,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "EFe9ilDOLvA5"
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1747138233985,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "VWfT1sEkLu-U"
   },
   "outputs": [],
   "source": [
    "class ConvolutionModule(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, activation = Swish(), bias= True):\n",
    "        super().__init__()\n",
    "        self.pointwise_conv1 = nn.Conv1d(channels, 2 * channels, kernel_size=1, stride=1, padding=0, bias=bias)\n",
    "        self.depthwise_conv = nn.Conv1d(channels, channels, kernel_size, stride=1, padding=(kernel_size - 1) // 2, groups=channels, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(channels)\n",
    "        self.pointwise_conv2 = nn.Conv1d(channels, channels, kernel_size=1, stride=1, padding=0, bias=bias)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # (batch, channels, time)\n",
    "        x = self.pointwise_conv1(x)  # (batch, 2*channels, time)\n",
    "        x_act, x_gate = x.chunk(2, dim=1)  # (batch, channels, time) each\n",
    "        x = x_act * torch.sigmoid(x_gate) # GLU\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pointwise_conv2(x)\n",
    "        return x.transpose(1, 2) # (batch, time, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747138233986,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "RJPq16k4L1Vi"
   },
   "outputs": [],
   "source": [
    "class FeedForwardModule(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout, activation = Swish()):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1747138234002,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "JYjzPl_LL4mo"
   },
   "outputs": [],
   "source": [
    "class ConformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, conv_kernel_size, dropout):\n",
    "        super().__init__()\n",
    "        self.ffn1 = FeedForwardModule(d_model, d_ff, dropout)\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, n_head, dropout=dropout, batch_first=True)\n",
    "        self.conv_module = ConvolutionModule(d_model, conv_kernel_size)\n",
    "        self.ffn2 = FeedForwardModule(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.norm4 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask) :\n",
    "        # FFNN 1\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.ffn1(x)\n",
    "        x = self.dropout(x) * 0.5 + residual # Half-step residual\n",
    "\n",
    "        # Multi-Head Self-Attention Part\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x_attn, _ = self.self_attn(x, x, x, key_padding_mask=src_key_padding_mask)\n",
    "        x = self.dropout(x_attn) + residual\n",
    "\n",
    "        # Convolution Part\n",
    "        residual = x\n",
    "        x = self.norm3(x)\n",
    "        x = self.conv_module(x)\n",
    "        x = self.dropout(x) + residual\n",
    "\n",
    "        # FFNN 2\n",
    "        residual = x\n",
    "        x = self.norm4(x)\n",
    "        x = self.ffn2(x)\n",
    "        x = self.dropout(x) * 0.5 + residual # Half-step residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1747138234003,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "xnJralvBL6nw"
   },
   "outputs": [],
   "source": [
    "class AttentiveStatisticsPooling(nn.Module):\n",
    "    def __init__(self, input_dim, attention_dim):\n",
    "        super().__init__()\n",
    "        self.attention_mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, attention_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(attention_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, attention_mask):\n",
    "        # x shape: (batch, seq_len, input_dim)\n",
    "        # attention_mask shape: (batch, seq_len), 1 for valid, 0 for pad\n",
    "\n",
    "        attn_weights = self.attention_mlp(x).squeeze(-1)  # (batch, seq_len)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attn_weights = attn_weights.masked_fill(attention_mask == 0, -1e9) # Mask before softmax\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=1)  # (batch, seq_len)\n",
    "        attn_weights_expanded = attn_weights.unsqueeze(-1) # (batch, seq_len, 1)\n",
    "\n",
    "        weighted_mean = torch.sum(x * attn_weights_expanded, dim=1) # (batch, input_dim)\n",
    "\n",
    "        # Weighted standard deviation\n",
    "        weighted_var = torch.sum((x**2) * attn_weights_expanded, dim=1) - weighted_mean**2\n",
    "        weighted_std = torch.sqrt(weighted_var.clamp(min=1e-9)) # (batch, input_dim)\n",
    "\n",
    "        # Concatenate mean and std\n",
    "        pooled_output = torch.cat((weighted_mean, weighted_std), dim=1) # (batch, 2 * input_dim)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1747138234020,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "CrneBk9cL6k6"
   },
   "outputs": [],
   "source": [
    "class sps_ConformerWavLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(PRETRAINED_SSL_MODEL, trust_remote_code=True)\n",
    "        self.wavlm = WavLMModel.from_pretrained(PRETRAINED_SSL_MODEL, trust_remote_code=True)\n",
    "\n",
    "        if FINETUNE_SSL_MODEL:\n",
    "            if FINETUNE_SSL_LAYERS == 0: # Freeze all if 0 layers specified for fine-tuning\n",
    "                 for param in self.wavlm.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            elif FINETUNE_SSL_LAYERS > 0:\n",
    "                # Freeze all parameters first\n",
    "                for param in self.wavlm.parameters():\n",
    "                    param.requires_grad = False\n",
    "                # Unfreeze the feature projection layer (adapter)\n",
    "                if hasattr(self.wavlm, 'feature_projection'):\n",
    "                    for param in self.wavlm.feature_projection.parameters():\n",
    "                        param.requires_grad = True\n",
    "                # Unfreeze the top N encoder layers\n",
    "                if hasattr(self.wavlm, 'encoder') and hasattr(self.wavlm.encoder, 'layers'):\n",
    "                    num_total_layers = len(self.wavlm.encoder.layers)\n",
    "                    for i in range(num_total_layers - FINETUNE_SSL_LAYERS, num_total_layers):\n",
    "                        if i >= 0:\n",
    "                            for param in self.wavlm.encoder.layers[i].parameters():\n",
    "                                param.requires_grad = True\n",
    "\n",
    "        else: # Freeze entire SSL model if FINETUNE_SSL_MODEL is False\n",
    "            for param in self.wavlm.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.conformer_encoder = nn.Sequential(\n",
    "            *[ConformerBlock(\n",
    "                d_model=CONFORMER_INPUT_DIM,\n",
    "                n_head=CONFORMER_NHEAD,\n",
    "                d_ff=CONFORMER_INPUT_DIM * CONFORMER_FF_DIM_FACTOR,\n",
    "                conv_kernel_size=CONFORMER_CONV_KERNEL_SIZE,\n",
    "                dropout=CONFORMER_DROPOUT\n",
    "              ) for _ in range(CONFORMER_NUM_BLOCKS)]\n",
    "        )\n",
    "\n",
    "        self.pooling = AttentiveStatisticsPooling(CONFORMER_INPUT_DIM, ATTN_POOL_DIM)\n",
    "        pooled_output_dim = CONFORMER_INPUT_DIM * 2\n",
    "\n",
    "        self.heads = nn.ModuleDict()\n",
    "        for task_name, task_info in TASKS.items():\n",
    "            head_config = HEAD_CONFIGS[task_name]\n",
    "            output_dim = 1 if task_info['type'] == 'regression' else task_info.get('num_classes')\n",
    "\n",
    "            if output_dim is None:\n",
    "              print(f\"num_classes missing for {task_name}\")\n",
    "\n",
    "            self.heads[task_name] = nn.Sequential(\n",
    "                nn.Linear(pooled_output_dim, head_config['head_hidden_dim']), nn.ReLU(),\n",
    "                nn.Dropout(head_config['head_dropout_rate']),\n",
    "                nn.Linear(head_config['head_hidden_dim'], output_dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        current_device = waveform.device\n",
    "        inputs = self.feature_extractor(\n",
    "            [wav.cpu().numpy() for wav in waveform], # WavLM/W2V2 FE expects list of numpy\n",
    "            sampling_rate=SAMPLE_RATE,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\"\n",
    "        )\n",
    "        input_values = inputs.input_values.to(current_device)\n",
    "\n",
    "        attention_mask_ssl_input = inputs.attention_mask.to(current_device) if hasattr(inputs, 'attention_mask') and inputs.attention_mask is not None else None\n",
    "\n",
    "        wavlm_outputs = self.wavlm(\n",
    "            input_values,\n",
    "            attention_mask=attention_mask_ssl_input,\n",
    "            output_hidden_states=False\n",
    "        )\n",
    "        hidden_states = wavlm_outputs.last_hidden_state\n",
    "\n",
    "        # Conformer expects src_key_padding_mask: (batch, seq_len_ssl), True for padded\n",
    "        # attention_mask_ssl_input is (batch, seq_len_ssl), 1 for valid, 0 for pad\n",
    "        # So, src_key_padding_mask is (attention_mask_ssl_input == 0)\n",
    "        if attention_mask_ssl_input is not None:\n",
    "            output_seq_len = hidden_states.shape[1]\n",
    "            if attention_mask_ssl_input.shape[1] > output_seq_len:\n",
    "                 conformer_padding_mask = (attention_mask_ssl_input[:, :output_seq_len] == 0)\n",
    "\n",
    "            elif attention_mask_ssl_input.shape[1] < output_seq_len:\n",
    "                 conformer_padding_mask = torch.zeros(hidden_states.shape[0], output_seq_len, dtype=torch.bool, device=current_device)\n",
    "\n",
    "            else:\n",
    "                 conformer_padding_mask = (attention_mask_ssl_input == 0)\n",
    "        else:\n",
    "            conformer_padding_mask = torch.zeros(hidden_states.shape[0], hidden_states.shape[1], dtype=torch.bool, device=current_device)\n",
    "\n",
    "\n",
    "\n",
    "        conformer_output = hidden_states\n",
    "        for block in self.conformer_encoder:\n",
    "            conformer_output = block(conformer_output, src_key_padding_mask=conformer_padding_mask)\n",
    "\n",
    "        # For AttentiveStatisticsPooling, we need a mask where 1 is valid, 0 is pad\n",
    "        pooling_attention_mask = ~conformer_padding_mask\n",
    "\n",
    "        pooled_output = self.pooling(conformer_output, attention_mask=pooling_attention_mask)\n",
    "\n",
    "        predictions = {}\n",
    "        for task_name, head_module in self.heads.items():\n",
    "            task_prediction = head_module(pooled_output)\n",
    "            if TASKS[task_name]['type'] == 'regression':\n",
    "                predictions[task_name] = task_prediction.squeeze(-1)\n",
    "            else:\n",
    "                predictions[task_name] = task_prediction\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747138234023,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "EgHMMzGML_5U",
    "outputId": "96898060-4861-4a82-dd10-3c0625ced19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {DEVICE}\")\n",
    "random.seed(VAL_SPLIT_SEED)\n",
    "np.random.seed(VAL_SPLIT_SEED)\n",
    "torch.manual_seed(VAL_SPLIT_SEED)\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "  torch.cuda.manual_seed_all(VAL_SPLIT_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1747138234067,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "g1dnSiK9MC49",
    "outputId": "ae00b471-06fb-4049-b89e-d4b21b27fc84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw train data: 4490 rows, raw test data: 1640 rows\n",
      "Processed train data: 4490 rows, Processed test data: 1640 rows\n"
     ]
    }
   ],
   "source": [
    "full_train_df_raw = pd.read_csv(TRAIN_CSV_PATH)\n",
    "test_df_raw = pd.read_csv(TEST_CSV_PATH)\n",
    "print(f\"Loaded raw train data: {len(full_train_df_raw)} rows, raw test data: {len(test_df_raw)} rows\")\n",
    "\n",
    "cols_to_drop = ['index', 'Use_x', 'DR', 'Ethnicity']\n",
    "full_train_df = full_train_df_raw.drop(columns=[c for c in cols_to_drop if c in full_train_df_raw.columns], errors='ignore')\n",
    "test_df = test_df_raw.drop(columns=[c for c in cols_to_drop if c in test_df_raw.columns], errors='ignore')\n",
    "\n",
    "critical_cols = ['FilePath'] + list(TASKS.keys())\n",
    "full_train_df.dropna(subset=critical_cols, inplace=True)\n",
    "test_df.dropna(subset=critical_cols, inplace=True)\n",
    "\n",
    "full_train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Processed train data: {len(full_train_df)} rows, Processed test data: {len(test_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747138234070,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "WqxXC_VhMGNa",
    "outputId": "80cb1642-14cf-431b-8418-58dc4e654638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating normalization stats and mappings...\n",
      "  Age stats: Mean=30.29, Std=7.77\n",
      "  Gender mapping: {'F': 0, 'M': 1}, Num Classes: 2\n",
      "  Height stats: Mean=175.75, Std=9.52\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating normalization stats and mappings...\")\n",
    "for task_name, task_info in TASKS.items():\n",
    "    if task_info['type'] == 'regression':\n",
    "        mean = full_train_df[task_name].astype(float).mean()\n",
    "        std = full_train_df[task_name].astype(float).std()\n",
    "\n",
    "        NORM_STATS[task_name]['mean'] = mean\n",
    "        NORM_STATS[task_name]['std'] = std if (np.isfinite(std) and std > 1e-6) else 1.0\n",
    "\n",
    "        print(f\"  {task_name.capitalize()} stats: Mean={NORM_STATS[task_name]['mean']:.2f}, Std={NORM_STATS[task_name]['std']:.2f}\")\n",
    "\n",
    "    elif task_info['type'] == 'classification':\n",
    "        if task_name == 'Gender':\n",
    "            cats = sorted(list(full_train_df[task_name].astype(str).str.upper().unique()))\n",
    "            TASKS[task_name]['num_classes'] = len(cats)\n",
    "\n",
    "            GENDER_MAP = {cat: i for i, cat in enumerate(cats)}\n",
    "            print(f\"  Gender mapping: {GENDER_MAP}, Num Classes: {TASKS[task_name]['num_classes']}\")\n",
    "\n",
    "        else:\n",
    "            TASKS[task_name]['num_classes'] = len(full_train_df[task_name].unique())\n",
    "            print(f\"  {task_name.capitalize()} Num Classes: {TASKS[task_name]['num_classes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747138234073,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "dx4xDWObMI2t",
    "outputId": "f4243aab-5d70-449b-941d-b850bb4e5de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data by SpeakerID...\n",
      "Data split: Train=3360, Val=1130, Test=1640\n"
     ]
    }
   ],
   "source": [
    "if 'SpeakerID' in full_train_df.columns:\n",
    "    print(\"Splitting data by SpeakerID...\")\n",
    "    speaker_ids = full_train_df['SpeakerID'].unique()\n",
    "    train_spk_ids, val_spk_ids = train_test_split(speaker_ids, test_size=VAL_SPLIT_RATIO, random_state=VAL_SPLIT_SEED)\n",
    "\n",
    "    train_df, val_df = full_train_df[full_train_df['SpeakerID'].isin(train_spk_ids)].copy(), full_train_df[full_train_df['SpeakerID'].isin(val_spk_ids)].copy()\n",
    "\n",
    "else:\n",
    "    print(\"Warning: 'SpeakerID' not found. Performing random split.\")\n",
    "    train_df, val_df = train_test_split(full_train_df, test_size=VAL_SPLIT_RATIO, random_state=VAL_SPLIT_SEED)\n",
    "\n",
    "print(f\"Data split: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1747138234083,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "wJFG83xWMKKl"
   },
   "outputs": [],
   "source": [
    "train_dataset = TimitDataset(train_df, mode='train')\n",
    "val_dataset = TimitDataset(val_df, mode='eval')\n",
    "test_dataset = TimitDataset(test_df, mode='eval')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 1803,
     "status": "ok",
     "timestamp": 1747138235887,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "4-8N5yqsMMS_"
   },
   "outputs": [],
   "source": [
    "model = sps_ConformerWavLM().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747138235891,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "aTggfi86MMQp",
    "outputId": "c9772798-03c2-4eed-b925-2e424665d1ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: AdamW with differential LR (SSL factor: 0.1). SSL params count: 42\n"
     ]
    }
   ],
   "source": [
    "if FINETUNE_SSL_MODEL and FINETUNE_SSL_LAYERS != 0:\n",
    "    ssl_params = list(model.wavlm.parameters())\n",
    "    conformer_params = list(model.conformer_encoder.parameters())\n",
    "    pooling_params = list(model.pooling.parameters())\n",
    "    head_params = list(model.heads.parameters())\n",
    "\n",
    "    # Filter out frozen parameters from ssl_params\n",
    "    trainable_ssl_params = [p for p in ssl_params if p.requires_grad]\n",
    "\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': trainable_ssl_params, 'lr': LEARNING_RATE * SSL_FINETUNE_LR_FACTOR if trainable_ssl_params else LEARNING_RATE}, # Use smaller LR for SSL\n",
    "        {'params': conformer_params, 'lr': LEARNING_RATE},\n",
    "        {'params': pooling_params, 'lr': LEARNING_RATE},\n",
    "        {'params': head_params, 'lr': LEARNING_RATE}\n",
    "    ], weight_decay=OPTIMIZER_WEIGHT_DECAY)\n",
    "\n",
    "    print(f\"Optimizer: AdamW with differential LR (SSL factor: {SSL_FINETUNE_LR_FACTOR if trainable_ssl_params else 1.0}). SSL params count: {len(trainable_ssl_params)}\")\n",
    "\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=LEARNING_RATE, weight_decay=OPTIMIZER_WEIGHT_DECAY\n",
    "    )\n",
    "    print(\"Optimizer: AdamW with single LR for all trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747138235893,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "rWhagNWFMMOE"
   },
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "criterion_cls = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747138235894,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "cQdkfiq2MYGO"
   },
   "outputs": [],
   "source": [
    "main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                            mode=MONITOR_METRIC_MODE,\n",
    "                                                            factor=LR_SCHEDULER_FACTOR,\n",
    "                                                            patience=LR_SCHEDULER_PATIENCE,\n",
    "                                                            min_lr=MIN_LR, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747138235895,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "Zlv-jzjpMZZU"
   },
   "outputs": [],
   "source": [
    "def validate_epoch(val_loader, model, device):\n",
    "    model.eval()\n",
    "    running_task_losses_val = {task: 0.0 for task in TASKS}\n",
    "    num_samples_val = 0\n",
    "    criterion_reg_val, criterion_cls_val = nn.MSELoss(reduction='sum'), nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(val_loader):\n",
    "            if batch_data is None:\n",
    "              continue\n",
    "\n",
    "            wav, targets = batch_data\n",
    "            if wav.numel() == 0 or not targets:\n",
    "              continue\n",
    "\n",
    "            wav, targets_device = wav.to(device), {k: v.to(device) for k, v in targets.items()}\n",
    "\n",
    "            current_batch_size = wav.size(0)\n",
    "            predictions = model(wav)\n",
    "            valid_batch = True\n",
    "\n",
    "            for task_name, task_info in TASKS.items():\n",
    "                if task_name not in predictions or task_name not in targets_device:\n",
    "                  valid_batch = False\n",
    "                  break\n",
    "\n",
    "                pred_val, target_val = predictions[task_name], targets_device[task_name]\n",
    "                if task_info['type'] == 'regression' and pred_val.shape != target_val.shape:\n",
    "                  target_val = target_val.view_as(pred_val)\n",
    "\n",
    "                loss_val = criterion_reg_val(pred_val, target_val) if task_info['type'] == 'regression' else criterion_cls_val(pred_val, target_val)\n",
    "\n",
    "                if torch.isnan(loss_val) or torch.isinf(loss_val):\n",
    "                  running_task_losses_val[task_name] += 1e9 * current_batch_size\n",
    "                  valid_batch = False\n",
    "                  break\n",
    "\n",
    "                else:\n",
    "                  running_task_losses_val[task_name] += loss_val.item()\n",
    "\n",
    "\n",
    "            if not valid_batch:\n",
    "              continue\n",
    "\n",
    "            num_samples_val += current_batch_size\n",
    "\n",
    "\n",
    "    avg_task_losses_val, weighted_val_loss = {}, 0.0\n",
    "    if num_samples_val > 0:\n",
    "        for task_name in TASKS.keys():\n",
    "            avg_loss = running_task_losses_val[task_name] / num_samples_val\n",
    "            avg_task_losses_val[task_name] = avg_loss\n",
    "            if task_name in EVAL_LOSS_WEIGHTS:\n",
    "               weighted_val_loss += EVAL_LOSS_WEIGHTS[task_name] * avg_loss\n",
    "\n",
    "    else:\n",
    "        for task_name in TASKS.keys():\n",
    "          avg_task_losses_val[task_name] = float('inf')\n",
    "\n",
    "        weighted_val_loss = float('inf')\n",
    "\n",
    "\n",
    "\n",
    "    return avg_task_losses_val, weighted_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2290813,
     "status": "ok",
     "timestamp": 1747141418551,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "rHdXdjTnMg4Q",
    "outputId": "9508bd05-aa54-4271-d8d4-8607f439a1c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training (WavLM-Conformer Model) ---\n",
      "Warm-up Epoch 1: LR SSL: 1.00e-06, LR Main: 1.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 Summary: AvgTrL: 0.6999 | Avg ageTrL: 0.8757 | Avg GenTrL: 0.4210 | Avg heiTrL: 0.7445\n",
      "E1 Validation: WValL: 0.6698 | Avg ageVaL: 1.2315 | Avg GenVaL: 0.1324 | Avg heiVaL: 0.6209 | LR SSL: 1.00e-06, LR Main: 1.00e-05\n",
      "  Best model saved! E1, ValM: 0.6698\n",
      "Warm-up Epoch 2: LR SSL: 2.00e-06, LR Main: 2.00e-05\n",
      "E2 Summary: AvgTrL: 0.4968 | Avg ageTrL: 0.7601 | Avg GenTrL: 0.1000 | Avg heiTrL: 0.5424\n",
      "E2 Validation: WValL: 0.6361 | Avg ageVaL: 1.2453 | Avg GenVaL: 0.0517 | Avg heiVaL: 0.5867 | LR SSL: 2.00e-06, LR Main: 2.00e-05\n",
      "  Best model saved! E2, ValM: 0.6361\n",
      "Warm-up Epoch 3: LR SSL: 3.00e-06, LR Main: 3.00e-05\n",
      "E3 Summary: AvgTrL: 0.4533 | Avg ageTrL: 0.6717 | Avg GenTrL: 0.0681 | Avg heiTrL: 0.5473\n",
      "E3 Validation: WValL: 0.5090 | Avg ageVaL: 0.9510 | Avg GenVaL: 0.0334 | Avg heiVaL: 0.5759 | LR SSL: 3.00e-06, LR Main: 3.00e-05\n",
      "  Best model saved! E3, ValM: 0.5090\n",
      "Warm-up Epoch 4: LR SSL: 4.00e-06, LR Main: 4.00e-05\n",
      "E4 Summary: AvgTrL: 0.4225 | Avg ageTrL: 0.6224 | Avg GenTrL: 0.0564 | Avg heiTrL: 0.5221\n",
      "E4 Validation: WValL: 0.7206 | Avg ageVaL: 1.0316 | Avg GenVaL: 0.2932 | Avg heiVaL: 0.9533 | LR SSL: 4.00e-06, LR Main: 4.00e-05\n",
      "  No improvement for 1 epoch(s). Best: 0.5090\n",
      "Warm-up Epoch 5: LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "E5 Summary: AvgTrL: 0.4083 | Avg ageTrL: 0.5769 | Avg GenTrL: 0.0616 | Avg heiTrL: 0.5301\n",
      "E5 Validation: WValL: 0.5215 | Avg ageVaL: 0.8766 | Avg GenVaL: 0.0490 | Avg heiVaL: 0.7561 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 2 epoch(s). Best: 0.5090\n",
      "E6 Summary: AvgTrL: 0.3829 | Avg ageTrL: 0.5358 | Avg GenTrL: 0.0578 | Avg heiTrL: 0.5043\n",
      "E6 Validation: WValL: 0.6422 | Avg ageVaL: 1.2284 | Avg GenVaL: 0.0921 | Avg heiVaL: 0.5701 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 3 epoch(s). Best: 0.5090\n",
      "E7 Summary: AvgTrL: 0.3598 | Avg ageTrL: 0.5016 | Avg GenTrL: 0.0396 | Avg heiTrL: 0.4910\n",
      "E7 Validation: WValL: 0.4631 | Avg ageVaL: 0.8556 | Avg GenVaL: 0.0232 | Avg heiVaL: 0.5579 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  Best model saved! E7, ValM: 0.4631\n",
      "E8 Summary: AvgTrL: 0.3406 | Avg ageTrL: 0.4755 | Avg GenTrL: 0.0250 | Avg heiTrL: 0.4763\n",
      "E8 Validation: WValL: 0.6288 | Avg ageVaL: 1.2378 | Avg GenVaL: 0.0104 | Avg heiVaL: 0.6472 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 1 epoch(s). Best: 0.4631\n",
      "E9 Summary: AvgTrL: 0.3334 | Avg ageTrL: 0.4515 | Avg GenTrL: 0.0388 | Avg heiTrL: 0.4703\n",
      "E9 Validation: WValL: 0.4988 | Avg ageVaL: 0.9246 | Avg GenVaL: 0.0190 | Avg heiVaL: 0.6066 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 2 epoch(s). Best: 0.4631\n",
      "E10 Summary: AvgTrL: 0.3234 | Avg ageTrL: 0.4400 | Avg GenTrL: 0.0275 | Avg heiTrL: 0.4639\n",
      "E10 Validation: WValL: 0.5056 | Avg ageVaL: 0.9549 | Avg GenVaL: 0.0179 | Avg heiVaL: 0.5821 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 3 epoch(s). Best: 0.4631\n",
      "E11 Summary: AvgTrL: 0.3042 | Avg ageTrL: 0.4076 | Avg GenTrL: 0.0207 | Avg heiTrL: 0.4500\n",
      "E11 Validation: WValL: 0.4576 | Avg ageVaL: 0.8324 | Avg GenVaL: 0.0117 | Avg heiVaL: 0.5996 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  Best model saved! E11, ValM: 0.4576\n",
      "E12 Summary: AvgTrL: 0.2942 | Avg ageTrL: 0.3952 | Avg GenTrL: 0.0230 | Avg heiTrL: 0.4307\n",
      "E12 Validation: WValL: 0.5382 | Avg ageVaL: 0.9446 | Avg GenVaL: 0.0816 | Avg heiVaL: 0.6383 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 1 epoch(s). Best: 0.4576\n",
      "E13 Summary: AvgTrL: 0.2821 | Avg ageTrL: 0.3651 | Avg GenTrL: 0.0318 | Avg heiTrL: 0.4216\n",
      "E13 Validation: WValL: 0.4865 | Avg ageVaL: 0.8860 | Avg GenVaL: 0.0212 | Avg heiVaL: 0.6184 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 2 epoch(s). Best: 0.4576\n",
      "E14 Summary: AvgTrL: 0.2753 | Avg ageTrL: 0.3619 | Avg GenTrL: 0.0235 | Avg heiTrL: 0.4115\n",
      "E14 Validation: WValL: 0.5944 | Avg ageVaL: 1.1085 | Avg GenVaL: 0.0216 | Avg heiVaL: 0.7119 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 3 epoch(s). Best: 0.4576\n",
      "E15 Summary: AvgTrL: 0.2673 | Avg ageTrL: 0.3395 | Avg GenTrL: 0.0238 | Avg heiTrL: 0.4147\n",
      "E15 Validation: WValL: 0.5048 | Avg ageVaL: 0.9428 | Avg GenVaL: 0.0151 | Avg heiVaL: 0.6085 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 4 epoch(s). Best: 0.4576\n",
      "E16 Summary: AvgTrL: 0.2463 | Avg ageTrL: 0.3089 | Avg GenTrL: 0.0178 | Avg heiTrL: 0.3913\n",
      "E16 Validation: WValL: 0.5138 | Avg ageVaL: 0.9544 | Avg GenVaL: 0.0258 | Avg heiVaL: 0.6084 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 5 epoch(s). Best: 0.4576\n",
      "E17 Summary: AvgTrL: 0.2478 | Avg ageTrL: 0.3233 | Avg GenTrL: 0.0167 | Avg heiTrL: 0.3782\n",
      "E17 Validation: WValL: 0.4851 | Avg ageVaL: 0.8336 | Avg GenVaL: 0.0364 | Avg heiVaL: 0.6855 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 6 epoch(s). Best: 0.4576\n",
      "E18 Summary: AvgTrL: 0.2388 | Avg ageTrL: 0.3123 | Avg GenTrL: 0.0173 | Avg heiTrL: 0.3622\n",
      "E18 Validation: WValL: 0.5675 | Avg ageVaL: 1.0481 | Avg GenVaL: 0.0289 | Avg heiVaL: 0.6835 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 7 epoch(s). Best: 0.4576\n",
      "E19 Summary: AvgTrL: 0.2229 | Avg ageTrL: 0.2775 | Avg GenTrL: 0.0141 | Avg heiTrL: 0.3590\n",
      "E19 Validation: WValL: 0.5805 | Avg ageVaL: 1.0368 | Avg GenVaL: 0.0719 | Avg heiVaL: 0.6853 | LR SSL: 5.00e-06, LR Main: 5.00e-05\n",
      "  No improvement for 8 epoch(s). Best: 0.4576\n",
      "E20 Summary: AvgTrL: 0.1815 | Avg ageTrL: 0.2314 | Avg GenTrL: 0.0077 | Avg heiTrL: 0.2887\n",
      "E20 Validation: WValL: 0.5503 | Avg ageVaL: 0.9942 | Avg GenVaL: 0.0230 | Avg heiVaL: 0.7170 | LR SSL: 1.00e-06, LR Main: 1.00e-05\n",
      "  No improvement for 9 epoch(s). Best: 0.4576\n",
      "E21 Summary: AvgTrL: 0.1605 | Avg ageTrL: 0.1959 | Avg GenTrL: 0.0069 | Avg heiTrL: 0.2669\n",
      "E21 Validation: WValL: 0.5650 | Avg ageVaL: 0.9881 | Avg GenVaL: 0.0244 | Avg heiVaL: 0.8002 | LR SSL: 1.00e-06, LR Main: 1.00e-05\n",
      "  No improvement for 10 epoch(s). Best: 0.4576\n",
      "E22 Summary: AvgTrL: 0.1663 | Avg ageTrL: 0.2100 | Avg GenTrL: 0.0114 | Avg heiTrL: 0.2630\n",
      "E22 Validation: WValL: 0.5755 | Avg ageVaL: 1.0550 | Avg GenVaL: 0.0272 | Avg heiVaL: 0.7131 | LR SSL: 1.00e-06, LR Main: 1.00e-05\n",
      "  No improvement for 11 epoch(s). Best: 0.4576\n",
      "E23 Summary: AvgTrL: 0.1473 | Avg ageTrL: 0.1864 | Avg GenTrL: 0.0061 | Avg heiTrL: 0.2362\n",
      "E23 Validation: WValL: 0.5608 | Avg ageVaL: 0.9713 | Avg GenVaL: 0.0450 | Avg heiVaL: 0.7713 | LR SSL: 1.00e-06, LR Main: 1.00e-05\n",
      "  No improvement for 12 epoch(s). Best: 0.4576\n",
      "E24 Summary: AvgTrL: 0.1532 | Avg ageTrL: 0.1895 | Avg GenTrL: 0.0081 | Avg heiTrL: 0.2499\n",
      "E24 Validation: WValL: 0.5655 | Avg ageVaL: 0.9676 | Avg GenVaL: 0.0513 | Avg heiVaL: 0.7895 | LR SSL: 1.00e-06, LR Main: 1.00e-05\n",
      "  No improvement for 13 epoch(s). Best: 0.4576\n",
      "E25 Summary: AvgTrL: 0.1466 | Avg ageTrL: 0.1826 | Avg GenTrL: 0.0110 | Avg heiTrL: 0.2343\n",
      "E25 Validation: WValL: 0.5559 | Avg ageVaL: 0.9665 | Avg GenVaL: 0.0283 | Avg heiVaL: 0.7897 | LR SSL: 1.00e-06, LR Main: 1.00e-05\n",
      "  No improvement for 14 epoch(s). Best: 0.4576\n",
      "E26 Summary: AvgTrL: 0.1391 | Avg ageTrL: 0.1766 | Avg GenTrL: 0.0076 | Avg heiTrL: 0.2207\n",
      "E26 Validation: WValL: 0.5795 | Avg ageVaL: 1.0286 | Avg GenVaL: 0.0274 | Avg heiVaL: 0.7852 | LR SSL: 1.00e-06, LR Main: 1.00e-05\n",
      "  No improvement for 15 epoch(s). Best: 0.4576\n",
      "Early stopping E26. No improvement for 15 epochs.\n",
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Starting Training (WavLM-Conformer Model ---\")\n",
    "best_val_metric = float('inf') if MONITOR_METRIC_MODE == 'min' else float('-inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "initial_lrs = [pg['lr'] for pg in optimizer.param_groups]\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss_epoch = 0.0\n",
    "    task_losses_epoch = {task: 0.0 for task in TASKS}\n",
    "    num_samples_processed = 0\n",
    "\n",
    "    # LR Warm-up\n",
    "    if epoch <= LR_WARMUP_EPOCHS:\n",
    "        for i, param_group in enumerate(optimizer.param_groups):\n",
    "            target_lr = initial_lrs[i]\n",
    "            param_group['lr'] = target_lr * (epoch / LR_WARMUP_EPOCHS)\n",
    "        current_lr_display = optimizer.param_groups[0]['lr'] # Display LR of the first group\n",
    "\n",
    "        if len(optimizer.param_groups) > 1:\n",
    "            current_lr_display_ssl = optimizer.param_groups[0]['lr']\n",
    "            current_lr_display_main = optimizer.param_groups[1]['lr']\n",
    "            print(f\"Warm-up Epoch {epoch}: LR SSL: {current_lr_display_ssl:.2e}, LR Main: {current_lr_display_main:.2e}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Warm-up Epoch {epoch}: LR: {current_lr_display:.2e}\")\n",
    "\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        if batch_data is None:\n",
    "          continue\n",
    "\n",
    "        wav, targets = batch_data\n",
    "        if wav.numel() == 0 or not targets:\n",
    "          continue\n",
    "\n",
    "        wav, targets_device = wav.to(DEVICE), {k: v.to(DEVICE) for k, v in targets.items()}\n",
    "        current_batch_size = wav.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(wav)\n",
    "        combined_loss_batch = torch.tensor(0.0, device=DEVICE)\n",
    "        current_batch_task_losses = {}\n",
    "        valid_batch_for_loss = True\n",
    "\n",
    "        for task_name, task_info in TASKS.items():\n",
    "            if task_name not in predictions or task_name not in targets_device:\n",
    "              valid_batch_for_loss = False\n",
    "              break\n",
    "\n",
    "            pred, target = predictions[task_name], targets_device[task_name]\n",
    "\n",
    "            if task_info['type'] == 'regression' and pred.shape != target.shape:\n",
    "              target = target.view_as(pred)\n",
    "\n",
    "            loss = criterion_reg(pred, target) if task_info['type'] == 'regression' else criterion_cls(pred, target)\n",
    "\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "              valid_batch_for_loss = False\n",
    "              break\n",
    "\n",
    "            combined_loss_batch += task_info['loss_weight'] * loss\n",
    "            current_batch_task_losses[task_name] = loss.item()\n",
    "\n",
    "        if valid_batch_for_loss:\n",
    "            combined_loss_batch.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=GRADIENT_CLIP_MAX_NORM)\n",
    "            optimizer.step()\n",
    "            total_loss_epoch += combined_loss_batch.item() * current_batch_size\n",
    "\n",
    "            for task_name, loss_item in current_batch_task_losses.items():\n",
    "                task_losses_epoch[task_name] += loss_item * current_batch_size\n",
    "\n",
    "            num_samples_processed += current_batch_size\n",
    "            # if (batch_idx + 1) % 50 == 0:\n",
    "            #      print(f\"  E{epoch} B{batch_idx+1}/{len(train_loader)} | BLoss: {combined_loss_batch.item():.3f} | \" + \\\n",
    "            #            \" | \".join([f\"{k[:3]}L: {v:.3f}\" for k,v in current_batch_task_losses.items()]))\n",
    "\n",
    "    avg_loss_epoch = total_loss_epoch/num_samples_processed if num_samples_processed > 0 else float('inf')\n",
    "    avg_task_train_losses = {k:v/num_samples_processed if num_samples_processed > 0 else float('inf') for k,v in task_losses_epoch.items()}\n",
    "    print(f\"E{epoch} Summary: AvgTrL: {avg_loss_epoch:.4f} | \" + \\\n",
    "          \" | \".join([f\"Avg {k[:3]}TrL: {v:.4f}\" for k,v in avg_task_train_losses.items()]))\n",
    "\n",
    "    if len(val_loader) > 0:\n",
    "        avg_task_val_losses, current_val_metric = validate_epoch(val_loader, model, DEVICE)\n",
    "        val_loss_str = \" | \".join([f\"Avg {k[:3]}VaL: {v:.4f}\" for k,v in avg_task_val_losses.items()])\n",
    "\n",
    "        current_lr_display = optimizer.param_groups[0]['lr']\n",
    "        lr_info_str = f\"LR: {current_lr_display:.2e}\"\n",
    "        if len(optimizer.param_groups) > 1:\n",
    "             lr_info_str = f\"LR SSL: {optimizer.param_groups[0]['lr']:.2e}, LR Main: {optimizer.param_groups[1]['lr']:.2e}\"\n",
    "\n",
    "        print(f\"E{epoch} Validation: WValL: {current_val_metric:.4f} | {val_loss_str} | {lr_info_str}\")\n",
    "\n",
    "        if epoch > LR_WARMUP_EPOCHS:\n",
    "            main_scheduler.step(current_val_metric)\n",
    "\n",
    "        if (MONITOR_METRIC_MODE == 'min' and current_val_metric < best_val_metric) or \\\n",
    "           (MONITOR_METRIC_MODE == 'max' and current_val_metric > best_val_metric):\n",
    "            best_val_metric, epochs_no_improve = current_val_metric, 0\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_state, CKPT_PATH)\n",
    "            print(f\"  Best model saved! E{epoch}, ValM: {best_val_metric:.4f}\")\n",
    "\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  No improvement for {epochs_no_improve} epoch(s). Best: {best_val_metric:.4f}\")\n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"Early stopping E{epoch}. No improvement for {EARLY_STOPPING_PATIENCE} epochs.\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "      print(\"Skipping validation.\")\n",
    "\n",
    "\n",
    "print(\"--- Training Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1747141418571,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "9D2s07jXMmrA",
    "outputId": "54853827-1d8c-4a3a-9681-24b65b25243e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating on Test Set with Best Model (WavLM-Conformer) ---\n",
      "Loading best model from memory (ValM: 0.4576)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating on Test Set with Best Model (WavLM-Conformer) ---\")\n",
    "if best_model_state is not None:\n",
    "    print(f\"Loading best model from memory (ValM: {best_val_metric:.4f})\")\n",
    "    model.load_state_dict(best_model_state)\n",
    "elif os.path.exists(CKPT_PATH):\n",
    "    print(f\"Loading best model from checkpoint: {CKPT_PATH}\")\n",
    "    model.load_state_dict(torch.load(CKPT_PATH, map_location=DEVICE))\n",
    "else:\n",
    "  print(\"No best model state found. Evaluating with the last model state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20850,
     "status": "ok",
     "timestamp": 1747141906881,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "byARvqaw-WPl",
    "outputId": "ee4e00d4-a128-4b39-96cc-21b0666b0d86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluated test batch 20/52\n",
      "  Evaluated test batch 40/52\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_targets_test, all_preds_test = {t:[] for t in TASKS}, {t:[] for t in TASKS}\n",
    "running_task_losses_test, num_samples_test = {t:0.0 for t in TASKS}, 0\n",
    "crit_reg_test, crit_cls_test = nn.MSELoss(reduction='sum'), nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch_data in enumerate(test_loader):\n",
    "        if batch_data is None:\n",
    "          continue\n",
    "\n",
    "        wav, targets = batch_data\n",
    "        if wav.numel() == 0 or not targets:\n",
    "          continue\n",
    "\n",
    "        wav, targets_dev = wav.to(DEVICE), {k:v.to(DEVICE) for k,v in targets.items()}\n",
    "        current_batch_size = wav.size(0)\n",
    "        predictions = model(wav)\n",
    "\n",
    "        for task_name, task_info in TASKS.items():\n",
    "            if task_name not in predictions or task_name not in targets_dev:\n",
    "              continue\n",
    "\n",
    "            pred_v, target_v = predictions[task_name], targets_dev[task_name]\n",
    "            if task_info['type'] == 'regression' and pred_v.shape != target_v.shape:\n",
    "              target_v=target_v.view_as(pred_v)\n",
    "\n",
    "            loss_v = crit_reg_test(pred_v, target_v) if task_info['type']=='regression' else crit_cls_test(pred_v, target_v)\n",
    "\n",
    "            running_task_losses_test[task_name] += loss_v.item()\n",
    "            pred_cpu, targ_cpu = pred_v.cpu(), targets[task_name]\n",
    "            if task_info['type'] == 'regression':\n",
    "                m, s = NORM_STATS[task_name]['mean'], NORM_STATS[task_name]['std']\n",
    "                pred_denorm = (pred_cpu * (s if s > 1e-6 else 1.0)) + m\n",
    "                targ_denorm = (targ_cpu * (s if s > 1e-6 else 1.0)) + m\n",
    "                all_preds_test[task_name].extend(pred_denorm.tolist())\n",
    "                all_targets_test[task_name].extend(targ_denorm.tolist())\n",
    "\n",
    "            else:\n",
    "                all_preds_test[task_name].extend(torch.argmax(pred_cpu, dim=1).tolist())\n",
    "                all_targets_test[task_name].extend(targ_cpu.tolist())\n",
    "        num_samples_test += current_batch_size\n",
    "        if (batch_idx + 1) % 20 == 0:\n",
    "          print(f\"  Evaluated test batch {batch_idx+1}/{len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1747141912034,
     "user": {
      "displayName": "surge",
      "userId": "10562721468625119372"
     },
     "user_tz": -330
    },
    "id": "btG9gFtkxa0q",
    "outputId": "7e2f6f2c-bbb5-4fde-cda7-e420b10af471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Test Results (Best WavLM-Conformer Model) ---\n",
      "  Test MSE (age): 50.4608 (RMSE: 7.1036)\n",
      "  Test Accuracy (Gender): 0.9933\n",
      "  Test MSE (height): 52.9677 (RMSE: 7.2779)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics_test, avg_task_losses_test = {}, {}\n",
    "print(\"\\n--- Final Test Results (Best WavLM-Conformer Model) ---\")\n",
    "if num_samples_test > 0:\n",
    "    for task_name, task_info in TASKS.items():\n",
    "        avg_task_losses_test[task_name] = running_task_losses_test[task_name]/num_samples_test\n",
    "        # print(f\"  Avg Test Loss ({task_name}): {avg_task_losses_test[task_name]:.4f}\")\n",
    "        targets_np, preds_np = np.array(all_targets_test[task_name]), np.array(all_preds_test[task_name])\n",
    "\n",
    "        if len(targets_np) > 0 and len(targets_np) == len(preds_np):\n",
    "            if task_info['type'] == 'regression':\n",
    "                mse = mean_squared_error(targets_np, preds_np)\n",
    "                metrics_test[f\"{task_name}_mse\"] = mse\n",
    "                print(f\"  Test MSE ({task_name}): {mse:.4f} (RMSE: {np.sqrt(mse):.4f})\")\n",
    "\n",
    "            else:\n",
    "                acc = accuracy_score(targets_np, preds_np)\n",
    "                metrics_test[f\"{task_name}_acc\"] = acc\n",
    "                print(f\"  Test Accuracy ({task_name}): {acc:.4f}\")\n",
    "        else:\n",
    "          print(f\"  Could not calculate metric for {task_name}.\")\n",
    "\n",
    "\n",
    "else: print(\"No samples processed during final test evaluation.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x28ar2GdczqP"
   },
   "source": [
    "\n",
    "--- Final Test Results (WavLM-Conformer Model) ---\n",
    "\n",
    "with Age loss_weight: 0.4, Gender loss_weight: 0.4 and  Height loss_weight: 0.2\n",
    "\n",
    "  * Test MSE (age): 55.3258 (RMSE: 7.4381)\n",
    "  * Test Accuracy (Gender): 0.9945\n",
    "  * Test MSE (height): 54.2472 (RMSE: 7.3653)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__88ic_fx1Qr"
   },
   "source": [
    "\n",
    "--- Final Test Results (Best WavLM-Conformer Model) ---\n",
    "\n",
    "with Age loss_weight: 0.4, Gender loss_weight: 0.3 and Height loss_weight: 0.3\n",
    "  * Test MSE (age): 50.4608 (RMSE: 7.1036)\n",
    "  * Test Accuracy (Gender): 0.9933\n",
    "  * Test MSE (height): 52.9677 (RMSE: 7.2779)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM0qITddgOSVjYsPiY7e77U",
   "gpuType": "L4",
   "mount_file_id": "1qq9SJGQkRKIS86CRVTwHpUvMZO-hgrt7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
